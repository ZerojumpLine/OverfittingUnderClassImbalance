# -*- coding: utf-8 -*-
#  Default values are set internally, if the corresponding parameter is not found in the configuration file.

#  [Optional but highly suggested] The name will be used in the filenames when saving the model.
#  Default: "cnnModel"
modelName = "tinyCnn"

#  [Required] The main folder that the output will be placed.
folderForOutput = "../../../output/"


#  ================ MODEL PARAMETERS =================

#  [Required] The number of classes in the task. Including background!
numberOfOutputClasses = 5
#  [Required] The number of input channels, eg number of MRI modalities.
numberOfInputChannels = 2

#  +++++++++++Normal pathway+++++++++++
#  [Required] This list should have as many entries as the number of layers I want the normal-pathway to have.
#  Each entry is an integer that specifies the number of Feature Maps to use in each of the layers.
numberFMsPerLayerNormal = [4,5,6]
#  [Required] This list should have as many entries as the number of layers in the normal pathway.
#  Each entry should be a sublist with 3 entries. These should specify the dimensions of the kernel at the corresponding layer.
kernelDimPerLayerNormal = [ [3,3,3], [3,3,3], [3,3,3]]

#  +++++++++++Subsampled pathway+++++++++++
#  [Optional] Specify whether to use a subsampled pathway. If False, all subsampled-related parameters will be read but disregarded in the model-construction.
#  Default: False
useSubsampledPathway = True

subsampleFactor = [[3,3,3]]

#  +++++++++++Size of Image Segments+++++++++++
#  DeepMedic does not process patches of the image, but larger image-segments. Specify their size here.

#  [Required] Size of training segments influence the captured distribution of samples from the different classes (see DeepMedic paper)
segmentsDimTrain = [25,25,25]
#  [Optional] Bigger image segments for Inference are safe to use and only speed up the process. Only limitation is the GPU memory.
#  Default: equal to the training segment.
segmentsDimInference = [45,45,45]

#  +++++++++++Batch Sizes+++++++++++
#  [Required] The number of segments to create a batch.
#  The samples in a training-batch are all processed and one optimization step is performed.
#  Larger batches approximate the total data better and should positively impact optimization but are computationally more expensive (time and memory).
batchSizeTrain = 10
#  [Optionals] Batch sizes for validation and inference only influence the speed. The bigger the better. Depends on the segment size and the model size how big batches can be fit in memory.
#  Default: Equal to train-batch size.
batchSizeVal = 50
batchSizeInfer = 10
